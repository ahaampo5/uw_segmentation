{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee13fd0f-2b10-4de3-8d62-8feeee2f0f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import wandb \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import os, shutil, gc, yaml\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from glob import glob\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from attrdict import AttrDict\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from IPython import display as ipd\n",
    "from colorama import Fore, Back, Style\n",
    "c_ = Fore.GREEN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "import timm\n",
    "\n",
    "import rasterio\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "## custom\n",
    "from utils import *\n",
    "from data import *\n",
    "from model import *\n",
    "from scheduler import *\n",
    "from loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b47f4e-ca16-4278-ac50-df295c3d541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################  config  #################\n",
    "config_name = 'unet-efficient-b3.yaml' # cuda:0\n",
    "# config_name = 'unext-resnext101_32x4d.yaml' # cuda:1\n",
    "\n",
    "with open(f'./configs/{config_name}', 'r') as f:\n",
    "    CFG = AttrDict(yaml.load(f, yaml.FullLoader))\n",
    "print(CFG)\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    val_scores = []\n",
    "    class_scores = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid ')\n",
    "    for step, (images, masks) in pbar:        \n",
    "        images  = images.to(device, dtype=torch.float)\n",
    "        masks   = masks.to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        y_pred  = model(images)\n",
    "        loss    = criterion(y_pred, masks)\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        y_pred = nn.Sigmoid()(y_pred)\n",
    "        \n",
    "        train_dice1 = dice_coef(masks[:,0,:,:].unsqueeze(1), y_pred[:,0,:,:].unsqueeze(1)).cpu().detach().numpy()\n",
    "        train_dice2 = dice_coef(masks[:,1,:,:].unsqueeze(1), y_pred[:,1,:,:].unsqueeze(1)).cpu().detach().numpy()\n",
    "        train_dice3 = dice_coef(masks[:,2,:,:].unsqueeze(1), y_pred[:,2,:,:].unsqueeze(1)).cpu().detach().numpy()\n",
    "        class_scores.append([train_dice1, train_dice2, train_dice3])\n",
    "        \n",
    "        val_dice = dice_coef(masks, y_pred).cpu().detach().numpy()\n",
    "        val_jaccard = iou_coef(masks, y_pred).cpu().detach().numpy()\n",
    "        val_scores.append([val_dice, val_jaccard])\n",
    "        \n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(valid_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_memory=f'{mem:0.2f} GB')\n",
    "        \n",
    "    val_scores  = np.mean(val_scores, axis=0)\n",
    "    class_scores = np.mean(class_scores, axis=0)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss, val_scores, class_scores\n",
    "\n",
    "def run_training(model, optimizer, scheduler, device, num_epochs):\n",
    "    # To automatically log gradients\n",
    "    wandb.watch(model, log_freq=100)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "        \n",
    "    valid_loss, valid_scores, valid_class_scores = valid_one_epoch(model, valid_loader, \n",
    "                                             device=CFG.device, \n",
    "                                             epoch=epoch)\n",
    "    valid_dice, valid_jaccard = valid_scores\n",
    "\n",
    "    print(\"valid class score\", valid_class_scores, np.mean(valid_class_scores, axis=0))\n",
    "\n",
    "    history['Valid Loss'].append(valid_loss)\n",
    "    history['Valid Dice'].append(valid_dice)\n",
    "    history['Valid Jaccard'].append(valid_jaccard)\n",
    "\n",
    "    print(f'Valid Dice: {valid_dice:0.4f} | Valid Jaccard: {valid_jaccard:0.4f}')\n",
    "\n",
    "    # deep copy the model\n",
    "    if valid_dice >= best_dice:\n",
    "        print(f\"{c_}Valid Score Improved ({best_dice:0.4f} ---> {valid_dice:0.4f})\")\n",
    "        best_dice    = valid_dice\n",
    "        best_jaccard = valid_jaccard\n",
    "        best_epoch   = epoch\n",
    "        run.summary[\"Best Dice\"]    = best_dice\n",
    "        run.summary[\"Best Jaccard\"] = best_jaccard\n",
    "        run.summary[\"Best Epoch\"]   = best_epoch\n",
    "        best_model_wts = deepcopy(model.state_dict())\n",
    "        PATH = f\"./pths/{CFG.comment}/best_epoch-{fold:02d}-dice{best_dice:.4f}.bin\"\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "        # Save a model file from the current directory\n",
    "        # wandb.save(PATH)\n",
    "        print(f\"Model Saved{sr_}\")\n",
    "\n",
    "    last_model_wts = deepcopy(model.state_dict())\n",
    "    PATH = f\"./pths/{CFG.comment}/last_epoch-{fold:02d}.bin\"\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "\n",
    "    print(); print()\n",
    "    \n",
    "    print(\"Best Score: {:.4f}\".format(best_jaccard))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "\n",
    "os.makedirs(f\"./pths/{CFG.comment}\", exist_ok=True) \n",
    "\n",
    "set_seed(CFG.seed)\n",
    "\n",
    "# data setting\n",
    "# print(pd, glob) \n",
    "path_df = pd.DataFrame(glob.glob(CFG.data_root), columns=['image_path'])\n",
    "path_df['mask_path'] = path_df.image_path.str.replace('image','mask')\n",
    "path_df['id'] = path_df.image_path.map(lambda x: x.split('/')[-1].replace('.npy',''))\n",
    "\n",
    "df = pd.read_csv('./train_.csv')\n",
    "df['segmentation'] = df.segmentation.fillna('')\n",
    "df['rle_len'] = df.segmentation.map(len)\n",
    "\n",
    "df2 = df.groupby(['id'])['segmentation'].agg(list).to_frame().reset_index() # rle list of each id\n",
    "df2 = df2.merge(df.groupby(['id'])['rle_len'].agg(sum).to_frame().reset_index()) # total length of all rles of each id\n",
    "\n",
    "df = df.drop(columns=['segmentation', 'class', 'rle_len'])\n",
    "df = df.groupby(['id']).head(1).reset_index(drop=True)\n",
    "df = df.merge(df2, on=['id'])\n",
    "df['empty'] = (df.rle_len==0) # empty masks\n",
    "\n",
    "df = df.drop(columns=['image_path','mask_path'])\n",
    "df = df.merge(path_df, on=['id'])\n",
    "\n",
    "fault1 = 'case7_day0'\n",
    "fault2 = 'case81_day30'\n",
    "df = df[~df['id'].str.contains(fault1) & ~df['id'].str.contains(fault2)].reset_index(drop=True)\n",
    "\n",
    "skf = StratifiedGroupKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['empty'], groups = df[\"case\"])):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "    \n",
    "if CFG.positive_only == True:\n",
    "    df = df[df['empty'] == False]\n",
    "    \n",
    "# env setting\n",
    "model = build_model(CFG)\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "scheduler = fetch_scheduler(optimizer, CFG)\n",
    "\n",
    "# print(df.image_path)\n",
    "for fold in CFG.folds:\n",
    "    print(f'#'*15)\n",
    "    print(f'### Fold: {fold}')\n",
    "    print(f'#'*15)\n",
    "    run = wandb.init(project='uw-segmentation', \n",
    "                     config={k:v for k, v in dict(vars(CFG)).items() if '__' not in k},\n",
    "                     anonymous='must',\n",
    "                     name=f\"fold-{fold}|dim-{CFG.img_size[0]}x{CFG.img_size[1]}|model-{CFG.model_name}\",\n",
    "                     group=CFG.comment,\n",
    "                    )\n",
    "    train_loader, valid_loader = prepare_loaders(fold, df, get_train_transforms(CFG), get_valid_transforms(CFG), CFG,  debug=CFG.debug)\n",
    "    model     = build_model(CFG)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "    scheduler = fetch_scheduler(optimizer, CFG)\n",
    "    model, history = run_training(model, optimizer, scheduler,\n",
    "                                  device=CFG.device,\n",
    "                                  num_epochs=CFG.epochs)\n",
    "    run.finish()\n",
    "    # display(ipd.IFrame(run.url, width=1000, height=720))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
